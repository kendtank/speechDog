# -*- coding: utf-8 -*-
"""
@Time    : 2025/09/22
@Author  : Kend
@FileName: preprocess_dog_barks_v2.py
@Software: PyCharm
@Description: é¢„å¤„ç†ç‹—å æ•°æ®é›† â†’ ç»Ÿä¸€é•¿åº¦ Mel/MFCC ç‰¹å¾ + æ•°æ®å¢å¼º
"""

import os
import numpy as np
import librosa
import random
from tqdm import tqdm

# --------------------
# å‚æ•°é…ç½®ï¼ˆé¢å‘ tinyML éªŒè¯ï¼‰
# --------------------
INPUT_DIR = r"D:\kend\myPython\speechDog-master\datasets\compare_dog"
OUTPUT_DIR = r"D:\kend\myPython\speechDog-master\datasets\dog_tiny_verification"

SAMPLE_RATE = 16000
TARGET_DURATION = 0.4  # ç§’
N_MELS = 32  # é™ä½åˆ° 32ï¼ŒåŒ¹é… 32x32 è¾“å…¥
N_FFT = 400  # 25ms
HOP_LENGTH = 200  # 12.5ms â†’ 0.4s / 0.0125s â‰ˆ 32 å¸§
TARGET_TIME_FRAMES = 32  # å›ºå®šæ—¶é—´å¸§æ•°

AUG_PER_SAMPLE = 6  # å‡å°‘åˆ° 6 æ¬¡ï¼Œç§»é™¤é«˜é£é™©å¢å¼º

os.makedirs(OUTPUT_DIR, exist_ok=True)
random.seed(42)
np.random.seed(42)


# --------------------
# å·¥å…·å‡½æ•°
# --------------------
def load_and_crop_to_peak(file, target_duration=TARGET_DURATION, sr=SAMPLE_RATE):
    """åŠ è½½å¹¶ä»¥èƒ½é‡å³°å€¼ä¸ºä¸­å¿ƒè£å‰ªåˆ°å›ºå®šæ—¶é•¿"""
    y, orig_sr = librosa.load(file, sr=None, mono=True)
    if orig_sr != sr:
        y = librosa.resample(y=y, orig_sr=orig_sr, target_sr=sr)

    target_samples = int(target_duration * sr)

    if len(y) < target_samples:
        # è¡¥é›¶å±…ä¸­
        pad_len = target_samples - len(y)
        left = pad_len // 2
        right = pad_len - left
        y = np.pad(y, (left, right), mode="constant")
    else:
        # ç”¨ RMS æ‰¾å³°å€¼å¸§
        rms = librosa.feature.rms(y=y, frame_length=N_FFT, hop_length=HOP_LENGTH)[0]
        if len(rms) == 0:
            center = len(y) // 2
        else:
            max_frame = np.argmax(rms)
            center = int(max_frame * HOP_LENGTH + N_FFT // 2)
        start = max(0, center - target_samples // 2)
        end = start + target_samples
        if end > len(y):
            end = len(y)
            start = max(0, end - target_samples)
        y = y[start:end]
    return y[:target_samples]  # ç¡®ä¿é•¿åº¦ä¸¥æ ¼ä¸€è‡´


def augment(y, sr=SAMPLE_RATE):
    """ä¿ç•™å¯¹å£°çº¹é²æ£’æ€§æœ‰ç›Šçš„å¢å¼º"""
    aug_list = [y]  # åŸå§‹æ ·æœ¬ï¼ˆç”¨äºæ³¨å†Œï¼‰

    # 1. åŠ ç™½å™ªå£°ï¼ˆä½å¼ºåº¦ï¼‰
    noise = np.random.normal(0, 0.003, len(y))
    aug_list.append(y + noise)

    # 2. éŸ³é‡æ‰°åŠ¨
    aug_list.append(y * random.uniform(0.85, 1.15))

    # 3. è½»å¾®æ—¶é—´æ‹‰ä¼¸ï¼ˆÂ±10%ï¼‰
    rate = random.uniform(0.92, 1.08)
    try:
        stretched = librosa.effects.time_stretch(y, rate=rate)
        if len(stretched) > len(y):
            stretched = stretched[:len(y)]
        else:
            stretched = np.pad(stretched, (0, len(y) - len(stretched)), mode='constant')
        aug_list.append(stretched)
    except:
        aug_list.append(y)

    # 4. è½»å¾®éŸ³é«˜åç§»ï¼ˆÂ±0.3 åŠéŸ³ï¼‰
    n_steps = random.uniform(-0.3, 0.3)
    try:
        pitched = librosa.effects.pitch_shift(y, sr=sr, n_steps=n_steps)
        aug_list.append(pitched)
    except:
        aug_list.append(y)

    # 5. è¾¹ç¼˜é™éŸ³ï¼ˆä»…å¼€å¤´æˆ–ç»“å°¾ï¼Œ10msï¼‰
    aug_y = y.copy()
    if random.random() > 0.5:
        start = 0
        length = int(0.01 * sr)
    else:
        start = len(y) - int(0.01 * sr)
        length = int(0.01 * sr)
    aug_y[start:start + length] = 0
    aug_list.append(aug_y)

    return aug_list


def extract_logmel_fixed(y, sr=SAMPLE_RATE, n_mels=N_MELS, n_time=TARGET_TIME_FRAMES):
    """æå– log-mel å¹¶å¼ºåˆ¶ resize åˆ° (n_mels, n_time)"""
    mel = librosa.feature.melspectrogram(
        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH, n_mels=n_mels
    )
    mel_db = librosa.power_to_db(mel, ref=np.max)

    # per-sample normalization
    mel_db = (mel_db - np.mean(mel_db)) / (np.std(mel_db) + 1e-6)

    # æ—¶é—´è½´æ’å€¼åˆ°å›ºå®šé•¿åº¦
    if mel_db.shape[1] > n_time:
        mel_db = mel_db[:, :n_time]
    else:
        mel_db = librosa.util.fix_length(mel_db, size=n_time, axis=1)

    return mel_db.astype(np.float32)


# --------------------
# ä¸»æµç¨‹
# --------------------
def process_dataset():
    for dog_id in tqdm(os.listdir(INPUT_DIR), desc="Processing dogs"):
        dog_path = os.path.join(INPUT_DIR, dog_id)
        if not os.path.isdir(dog_path):
            continue

        output_dir = os.path.join(OUTPUT_DIR, dog_id)
        os.makedirs(output_dir, exist_ok=True)

        for fname in os.listdir(dog_path):
            if not fname.lower().endswith(".wav"):
                continue

            wav_path = os.path.join(dog_path, fname)
            try:
                y = load_and_crop_to_peak(wav_path)
            except Exception as e:
                print(f"Failed to load {wav_path}: {e}")
                continue

            # ç”Ÿæˆå¢å¼ºç‰ˆæœ¬ï¼ˆç¬¬ä¸€ä¸ªæ˜¯åŸå§‹ï¼‰
            aug_versions = augment(y)

            base = os.path.splitext(fname)[0]
            for i, aug_y in enumerate(aug_versions):
                if i >= AUG_PER_SAMPLE + 1:  # åŸå§‹ + AUG_PER_SAMPLE ä¸ªå¢å¼º
                    break
                mel = extract_logmel_fixed(aug_y)
                # æ ‡è®°æ˜¯å¦ä¸ºåŸå§‹æ ·æœ¬ï¼ˆå¯ç”¨äºæ³¨å†Œï¼‰
                is_original = (i == 0)
                suffix = "_orig" if is_original else f"_aug{i}"
                np.save(
                    os.path.join(output_dir, f"{base}{suffix}.npy"),
                    mel.astype(np.float16)
                )

    print(f"âœ… é¢„å¤„ç†å®Œæˆï¼è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("ğŸ’¡ æç¤ºï¼šè®­ç»ƒæ—¶å¯ä½¿ç”¨æ‰€æœ‰æ ·æœ¬ï¼›æ³¨å†Œæ¨¡æ¿è¯·ä»…ä½¿ç”¨ *_orig.npy æ–‡ä»¶")


if __name__ == "__main__":
    process_dataset()