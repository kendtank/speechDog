# 音频处理原理

## 1. 声音是什么？
- 声音本质上是 **空气分子随时间的振动**。  
- 在数字系统中，它被表示为一个离散时间序列 $x[n]$。  
- 两个核心属性：  
  - **时间**：声音随时间演化  
  - **频率**：每秒振动的次数，单位 Hz（赫兹）  

**例子**：  
- 100 Hz → 低沉的狗吠  
- 2000 Hz → 尖锐的警报声  
- 人耳可听范围：**20 Hz ~ 20,000 Hz**  
- **狗的听觉范围更广**（可达 45 kHz），但吠叫能量主要集中在 **300–2000 Hz**

---

## 2. 采样率（Sampling Rate）
- 模拟声音需**离散化**才能被计算机处理。  
- **采样率** = 每秒采集的样本数（单位：Hz）  
- 常见选择：
  - **8 kHz**：电话语音（仅覆盖人声核心频段）  
  - **16 kHz**：语音/动物声识别黄金标准（覆盖 0–8 kHz，满足奈奎斯特）  
  - **44.1/48 kHz**：音乐/高保真录音  

**奈奎斯特定理**：  
> 采样率必须 ≥ 信号最高频率的 **2 倍**，才能无失真重建。  
> 例如：16 kHz 采样 → 最高可表示 **8 kHz** 的声音，**完全覆盖狗吠频段**。

---

## 3. 从时域到频域：傅里叶变换
- **时域波形**：直观但难以分析频率成分  
- **频域表示**：将声音分解为“不同频率 + 能量”的组合  
- **工具**：**FFT（快速傅里叶变换）** → 将短时帧 $x[n]$ 转为频谱  

**直觉**：  
> 就像把一段交响乐分解成小提琴、大提琴、鼓等单个乐器的声音。

---

## 4. Mel 频率与 Mel 滤波器组
- **问题**：人耳对频率的感知是非线性的！  
  - 对 **低频敏感**（100 Hz vs 200 Hz 差异明显）  
  - 对 **高频迟钝**（10,000 Hz vs 10,100 Hz 几乎无法区分）  
- **Mel 标度**：模拟人耳听感的非线性频率尺度  
  - 公式：  
    $$
    m = 2595 \cdot \log_{10}\left(1 + \frac{f}{700}\right)
    $$
    - $f$：物理频率（Hz）  
    - $m$：对应的 Mel 值  

**Mel 滤波器组**：  
> 在 FFT 频谱上叠加一组**三角形滤波器**，将线性频率压缩到 Mel 标度，得到 **Mel 能量谱**。

---

## 5. Log-Mel 特征（深度学习首选）
- 对 Mel 能量谱取 **对数（log）**：  
  $$
  \text{Log-Mel} = \log(\text{Mel} + \epsilon)
  $$
- **为什么加 log？**  
  - 声音强度在人耳中呈**对数感知**（分贝制）  
  - 压缩动态范围，使弱音和强音都能被有效表示  
- 输出：**Log-Mel Spectrogram**（时频图），形如一张“声音热力图”  

**优势**：  
- 保留完整的频谱结构（基频、谐波、共振峰）  
- **非常适合 CNN 提取局部模式**（如狗吠的谐波条纹）  
- **现代声纹识别、音频事件检测的标准输入**

---

## 6. MFCC（传统语音处理的代表）
- 在 Log-Mel 基础上，再做 **离散余弦变换（DCT）**  
- **目的**：  
  - 去除滤波器组间的相关性  
  - 压缩为少量（通常 13–40 维）**倒谱系数**  
  - 增强对录音设备/信道的鲁棒性  
- 常配合 **Δ / ΔΔ**（一阶/二阶差分）捕捉动态变化  

**关键区别**：  

| 特征 | 信息保留 | 适用任务 |
|------|--------|--------|
| **Log-Mel** | 保留完整频谱结构 | **声纹识别、生物声学、端到端学习** |
| **MFCC** | 丢弃频谱包络细节 | **传统语音识别（ASR）、关键词检测** |

> **重要提示**：  
> **MFCC 不适合声纹验证！**  
> 因为 DCT 步骤**故意模糊了个体声纹差异**（如共振峰形状），而这些正是区分“是不是我的狗”的关键。

---

## 7. 实用工程概念
- **VAD（Voice Activity Detection）**：检测有效语音段，跳过静音（节省算力）  
- **CMVN（倒谱均值方差归一化）**：消除设备增益差异（但 Log-Mel 通常用 per-sample norm）  
- **特征归一化**：  
  ```python
  mel = (mel - np.mean(mel)) / (np.std(mel) + 1e-6)  # per-sample 归一化
- **窗口与重叠：**
  - 窗长：25ms（400 点 @ 16kHz）
  - 帧移：10ms（160 点）→ 50% 重叠，平衡时间分辨率与计算量

## 8. 特征对比总结
| 特征 | 优点                   | 缺点                 | 推荐场景                 
|------|----------------------|--------------------|----------------------|
| **Log-Mel** | 保留完整频谱结构 适合CNN 对声纹敏感 | 维度较高（需 CNN 压缩）需归一化 | 声纹验证/识别、动物声学 |
| **MFCC** | 维度低（13–40）、传统 ASR 成熟 | 丢弃频谱包络细节、不适用声纹识别   | 语音识别、关键词检测 |
| Mel(线性) | 原始能量分布 | 动态范围过大， 不适合直接输入模型           | 仅用于可视化 |

## 9. tinyML应用
- 采样率：16 kHz(平衡性能与覆盖率)
- 特征选择：Log-Mel（32–40 频带 × 32–64 时间帧）
- 模型输入：2D CNN 处理 Log-Mel 图谱
- 量化：INT8 量化 embedding（32 维 → 32 字节/狗）

## 敬请期待后续
demo地址：[https://github.com/kendtank/dog_bark_verifier](https://github.com/kendtank/dog_bark_verifier)